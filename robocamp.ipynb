{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXLFY-uimljt",
        "outputId": "a78eb1d6-2b71-4e0a-98f1-bef4bd1d8a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BMQiRA_vFDJn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import os\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wk3sgCAxj6b"
      },
      "source": [
        "## Utility Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "asK8R6kQl-BT"
      },
      "outputs": [],
      "source": [
        "def load_images_from_directory(directory):\n",
        "    images = []\n",
        "    image_paths = []\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
        "            image_path = os.path.join(directory, filename)\n",
        "            img = load_img(image_path)\n",
        "            img = img.resize((150, 150))\n",
        "            img_array = img_to_array(img)\n",
        "            images.append(img_array)\n",
        "            image_paths.append(image_path)\n",
        "\n",
        "    return np.array(images), np.array(image_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0z4IPwZxN2M"
      },
      "source": [
        "## Data Augmentation\n",
        "\n",
        "Preferrably done only for training data\n",
        "\n",
        "Augment data collected to create more training data, including different picture rotation, zoom, flip, and brightness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LfAirG0peCC",
        "outputId": "25e33525-ef51-4c9f-b260-1cd7c8388200"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Augmenting 45 images in class 'green'...\n",
            "Augmenting 57 images in class 'red'...\n",
            "Augmenting 48 images in class 'yellow'...\n"
          ]
        }
      ],
      "source": [
        "base_folder = '/content/drive/MyDrive/datasetcollection/train/'\n",
        "classes = ['green', 'red', 'yellow']\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=(0.5, 1.5)\n",
        ")\n",
        "\n",
        "for c in classes:\n",
        "    class_path = os.path.join(base_folder, c)\n",
        "\n",
        "    # Delete all previously modified images\n",
        "    for fname in os.listdir(class_path):\n",
        "        if fname.startswith('modimage'):\n",
        "            os.remove(os.path.join(class_path, fname))\n",
        "\n",
        "    # Load images after deleting old modified ones\n",
        "    images, image_paths = load_images_from_directory(class_path)\n",
        "\n",
        "    # Get 25% of images\n",
        "    num_samples = int(len(images) *.25)\n",
        "    random_indices = np.random.choice(len(images), size=num_samples, replace=False)\n",
        "    sampled_images = images[random_indices]\n",
        "\n",
        "    print(f\"Augmenting {len(sampled_images)} images in class '{c}'...\")\n",
        "\n",
        "    for idx, image in enumerate(sampled_images):\n",
        "        image = np.expand_dims(image, axis=0)  # Make it batch size 1\n",
        "        aug_iter = datagen.flow(image, batch_size=1,\n",
        "                                save_to_dir=class_path,\n",
        "                                save_prefix='modimage',\n",
        "                                save_format='jpg')\n",
        "        for i in range(3):  # Create 3 augmentations per image\n",
        "            next(aug_iter)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "of7hxmzhxSS_"
      },
      "source": [
        "## CNN Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNLNLymX1tTq"
      },
      "outputs": [],
      "source": [
        "def get_dataset(directory):\n",
        "    classes = ['green', 'red', 'yellow']\n",
        "    X = []\n",
        "    y = []\n",
        "    for c in classes:\n",
        "        class_path = directory + c + \"/\"\n",
        "        images, image_paths = load_images_from_directory(class_path)\n",
        "        X.extend(images)\n",
        "        y.extend([c] * len(images))\n",
        "    return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gt5tzVOJ0c4x"
      },
      "outputs": [],
      "source": [
        "base_folder = '/content/drive/MyDrive/datasetcollection/'\n",
        "X_train, y_train = get_dataset(base_folder + 'train/')\n",
        "X_val, y_val = get_dataset(base_folder + 'val/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GGes097GrWo",
        "outputId": "e838e88d-ea9d-43ee-9323-5cfe319c642b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1038, 150, 150, 3), (277, 150, 150, 3), (1038,), (277,))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eTr9VooHEDb"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_val = X_val.astype('float32') / 255.0\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y_train = encoder.fit_transform(y_train.reshape(-1, 1))\n",
        "y_val = encoder.transform(y_val.reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQcVOsAc4aiY"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# 1st Convolutional Block\n",
        "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(150, 150, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# 2nd Convolutional Block\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# 3rd Convolutional Block\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Fully Connected Layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output Layer (assuming 3 classes)\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# only save best model, stop if no improvement\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
        "checkpoint = ModelCheckpoint('/content/drive/My Drive/RoboCarV5_bestModel.keras', monitor='val_loss', save_best_only=True,mode='min', verbose=1 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbPO14ZX4cer",
        "outputId": "0eeb7870-e407-48cb-b084-6fb040e610c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7654 - loss: 0.6335\n",
            "Epoch 1: val_loss improved from 1.04242 to 0.91555, saving model to /content/drive/My Drive/RoboCarV5_bestModel.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 2s/step - accuracy: 0.7654 - loss: 0.6334 - val_accuracy: 0.6823 - val_loss: 0.9155\n",
            "Epoch 2/12\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7453 - loss: 0.6291\n",
            "Epoch 2: val_loss did not improve from 0.91555\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 2s/step - accuracy: 0.7453 - loss: 0.6290 - val_accuracy: 0.6679 - val_loss: 0.9915\n",
            "Epoch 3/12\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7744 - loss: 0.5717\n",
            "Epoch 3: val_loss did not improve from 0.91555\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 2s/step - accuracy: 0.7744 - loss: 0.5717 - val_accuracy: 0.6390 - val_loss: 1.1916\n",
            "Epoch 4/12\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7887 - loss: 0.5749\n",
            "Epoch 4: val_loss did not improve from 0.91555\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 2s/step - accuracy: 0.7887 - loss: 0.5748 - val_accuracy: 0.6823 - val_loss: 1.2680\n",
            "Epoch 5/12\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7813 - loss: 0.5481\n",
            "Epoch 5: val_loss did not improve from 0.91555\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 2s/step - accuracy: 0.7813 - loss: 0.5481 - val_accuracy: 0.6751 - val_loss: 1.2707\n",
            "Epoch 6/12\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7868 - loss: 0.5400\n",
            "Epoch 6: val_loss did not improve from 0.91555\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 2s/step - accuracy: 0.7867 - loss: 0.5401 - val_accuracy: 0.6101 - val_loss: 1.5777\n",
            "Epoch 6: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x789d4ae4b150>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train, y_train, batch_size=4, epochs=12, validation_data=(X_val, y_val), callbacks=[checkpoint, early_stop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOUJwkXvjyLN"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/My Drive/RoboCarV4_6Epochs_NewRed.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsFJeh5PIOYK",
        "outputId": "c9391cda-846e-423f-d649-bbbbb330e1d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n"
          ]
        }
      ],
      "source": [
        "img = load_img('/content/drive/MyDrive/datasetcollection/val/red/rpicam_image123.jpg')\n",
        "img = img.resize((150, 150))\n",
        "img_array = img_to_array(img)\n",
        "img_array = np.array(img_array/255.0)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "prediction = model.predict(img_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "LFDhh4WZTw3g",
        "outputId": "29ccae35-c723-4434-eb9d-cf01a3e7aa34"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'encoder' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-480252b8fcf8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'encoder' is not defined"
          ]
        }
      ],
      "source": [
        "print(encoder.inverse_transform(prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuCwIVyq_ATg"
      },
      "source": [
        "## Optimize the Model for use on Pi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qP-yd6gHqtj7",
        "outputId": "34b7d284-db99-450f-aac4-ff2c102e044a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at '/tmp/tmp7jr29ki0'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 150, 150, 3), dtype=tf.float32, name='input_layer_2')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136699028357584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698941062608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698941061648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698941062416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698941055504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698941062992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698938491152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698938492688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698938492880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698938492112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698938491344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698938492496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698938493264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698938495568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698938495952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698938494608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698938495760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698938494992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698938497680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698938499216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698938500560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698938499600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698938500368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698938499408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698938504784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698938506320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698937393616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698937394192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698938507088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698938506512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698937397072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136698937399376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load Keras model\n",
        "model = tf.keras.models.load_model(\"/content/drive/MyDrive/RoboCarV5_bestModel.keras\")\n",
        "\n",
        "# Convert the model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # enables quantization\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the quantized model\n",
        "with open(\"/content/drive/My Drive/model_quant.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEy5o986T91y"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
